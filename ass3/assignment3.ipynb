{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 150 images belonging to 16 classes.\n",
      "Found 157 images belonging to 16 classes.\n"
     ]
    }
   ],
   "source": [
    "# Define the paths to your train and test data folders\n",
    "train_data_dir = 'train_data'\n",
    "test_data_dir = 'test_data'\n",
    "\n",
    "# Define the parameters for data augmentation for training data\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "# Define the parameters for rescaling the testing data\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Load the VGG16 pre-trained model without the top layer\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Generate batches of augmented data for training and validation\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_data_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "# num_classes is the number of bird species\n",
    "num_classes = train_generator.num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "5/5 [==============================] - 69s 15s/step - loss: 70.0222 - accuracy: 0.0733 - val_loss: 55.6618 - val_accuracy: 0.0637\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 58s 13s/step - loss: 29.3127 - accuracy: 0.1133 - val_loss: 14.2972 - val_accuracy: 0.1146\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 60s 13s/step - loss: 9.8447 - accuracy: 0.1133 - val_loss: 6.8923 - val_accuracy: 0.0637\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 56s 13s/step - loss: 4.4202 - accuracy: 0.2333 - val_loss: 4.5484 - val_accuracy: 0.1529\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 57s 12s/step - loss: 3.0465 - accuracy: 0.2533 - val_loss: 3.6620 - val_accuracy: 0.1465\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 57s 13s/step - loss: 2.4322 - accuracy: 0.3400 - val_loss: 3.4058 - val_accuracy: 0.1656\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 58s 13s/step - loss: 2.1477 - accuracy: 0.3133 - val_loss: 3.2219 - val_accuracy: 0.1911\n",
      "Epoch 8/10\n",
      "5/5 [==============================] - 58s 12s/step - loss: 2.0053 - accuracy: 0.3933 - val_loss: 3.2166 - val_accuracy: 0.1656\n",
      "Epoch 9/10\n",
      "5/5 [==============================] - 57s 13s/step - loss: 1.9197 - accuracy: 0.4267 - val_loss: 3.6637 - val_accuracy: 0.2293\n",
      "Epoch 10/10\n",
      "5/5 [==============================] - 58s 13s/step - loss: 1.7817 - accuracy: 0.4667 - val_loss: 3.5489 - val_accuracy: 0.2038\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x25c573b0f10>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Freeze the layers of the base model\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "# Build your model by adding the base model and additional layers\n",
    "model = Sequential()\n",
    "# model.add(base_model)\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', input_shape = (224, 224, 3)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "# model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "# model.add(MaxPooling2D((2, 2)))\n",
    "# model.add(Conv2D(256, (3, 3), activation='relu'))\n",
    "# model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "# model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))  \n",
    "\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(\n",
    "    train_generator,\n",
    "    batch_size=8,\n",
    "    steps_per_epoch=len(train_generator),\n",
    "    epochs=10,\n",
    "    validation_data=test_generator,\n",
    "    validation_steps=len(test_generator)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('birdWatchingPoggers.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "5/5 [==============================] - 69s 15s/step - loss: 2.7354 - accuracy: 0.1533 - val_loss: 3.0531 - val_accuracy: 0.0892\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 59s 13s/step - loss: 2.0055 - accuracy: 0.4533 - val_loss: 3.0831 - val_accuracy: 0.1847\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 60s 14s/step - loss: 1.8466 - accuracy: 0.5333 - val_loss: 3.2313 - val_accuracy: 0.2166\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 68s 15s/step - loss: 1.5723 - accuracy: 0.6200 - val_loss: 3.1958 - val_accuracy: 0.2293\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 59s 13s/step - loss: 1.3324 - accuracy: 0.7733 - val_loss: 3.1559 - val_accuracy: 0.2293\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 63s 14s/step - loss: 1.2171 - accuracy: 0.7667 - val_loss: 3.1164 - val_accuracy: 0.2166\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 62s 14s/step - loss: 1.0213 - accuracy: 0.8200 - val_loss: 3.0625 - val_accuracy: 0.2229\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 61s 14s/step - loss: 0.9648 - accuracy: 0.8600 - val_loss: 3.0219 - val_accuracy: 0.2166\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 63s 15s/step - loss: 0.7899 - accuracy: 0.8933 - val_loss: 2.9374 - val_accuracy: 0.2357\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 62s 14s/step - loss: 0.7291 - accuracy: 0.9133 - val_loss: 2.8211 - val_accuracy: 0.2357\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 63s 14s/step - loss: 0.6398 - accuracy: 0.9400 - val_loss: 2.7622 - val_accuracy: 0.2548\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 61s 13s/step - loss: 0.5534 - accuracy: 0.9533 - val_loss: 2.6999 - val_accuracy: 0.2866\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 61s 14s/step - loss: 0.5063 - accuracy: 0.9600 - val_loss: 2.6656 - val_accuracy: 0.2611\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 61s 14s/step - loss: 0.4051 - accuracy: 0.9733 - val_loss: 2.6363 - val_accuracy: 0.2930\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 60s 13s/step - loss: 0.3861 - accuracy: 0.9800 - val_loss: 2.5871 - val_accuracy: 0.3439\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 58s 13s/step - loss: 0.3166 - accuracy: 0.9867 - val_loss: 2.5982 - val_accuracy: 0.3503\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 59s 13s/step - loss: 0.2757 - accuracy: 0.9933 - val_loss: 2.6313 - val_accuracy: 0.3121\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 58s 13s/step - loss: 0.2733 - accuracy: 0.9733 - val_loss: 2.5240 - val_accuracy: 0.3312\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 60s 13s/step - loss: 0.2301 - accuracy: 0.9933 - val_loss: 2.4737 - val_accuracy: 0.3312\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 61s 14s/step - loss: 0.1974 - accuracy: 1.0000 - val_loss: 2.4510 - val_accuracy: 0.3631\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 61s 14s/step - loss: 0.1919 - accuracy: 1.0000 - val_loss: 2.4458 - val_accuracy: 0.3758\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 62s 14s/step - loss: 0.1554 - accuracy: 1.0000 - val_loss: 2.4413 - val_accuracy: 0.3822\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 59s 13s/step - loss: 0.1433 - accuracy: 1.0000 - val_loss: 2.4132 - val_accuracy: 0.3885\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 59s 13s/step - loss: 0.1250 - accuracy: 1.0000 - val_loss: 2.4033 - val_accuracy: 0.3949\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 59s 14s/step - loss: 0.1141 - accuracy: 1.0000 - val_loss: 2.3942 - val_accuracy: 0.3885\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 61s 14s/step - loss: 0.1046 - accuracy: 1.0000 - val_loss: 2.3703 - val_accuracy: 0.3694\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 61s 14s/step - loss: 0.0838 - accuracy: 1.0000 - val_loss: 2.3659 - val_accuracy: 0.3503\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 61s 14s/step - loss: 0.0922 - accuracy: 1.0000 - val_loss: 2.3639 - val_accuracy: 0.3439\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x25c5b626310>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "some_tuned_model = Sequential()\n",
    "some_tuned_model.add(base_model)\n",
    "some_tuned_model.add(Flatten())\n",
    "some_tuned_model.add(Dense(num_classes*4, activation='relu'))\n",
    "some_tuned_model.add(BatchNormalization())\n",
    "some_tuned_model.add(Dropout(0.2))\n",
    "some_tuned_model.add(Dense(num_classes*2, activation='relu'))\n",
    "some_tuned_model.add(Dense(num_classes, activation='softmax'))\n",
    "early_stop = EarlyStopping(monitor='accuracy',patience=8)\n",
    "\n",
    "# Compile the model\n",
    "some_tuned_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "some_tuned_model.fit(\n",
    "    train_generator,\n",
    "    batch_size=8,\n",
    "    steps_per_epoch=len(train_generator),\n",
    "    epochs=50,\n",
    "    validation_data=test_generator,\n",
    "    validation_steps=len(test_generator),\n",
    "    callbacks = early_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "some_tuned_model.save('vgg16_version.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'blasti': 0, 'bonegl': 1, 'brhkyt': 2, 'cbrtsh': 3, 'cmnmyn': 4, 'gretit': 5, 'hilpig': 6, 'himbul': 7, 'himgri': 8, 'hsparo': 9, 'indvul': 10, 'jglowl': 11, 'lbicrw': 12, 'mgprob': 13, 'rebimg': 14, 'wcrsrt': 15}\n"
     ]
    }
   ],
   "source": [
    "print(train_generator.class_indices)\n",
    "inverse_dict = {v: k for k, v in train_generator.class_indices.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'blasti', 1: 'bonegl', 2: 'brhkyt', 3: 'cbrtsh', 4: 'cmnmyn', 5: 'gretit', 6: 'hilpig', 7: 'himbul', 8: 'himgri', 9: 'hsparo', 10: 'indvul', 11: 'jglowl', 12: 'lbicrw', 13: 'mgprob', 14: 'rebimg', 15: 'wcrsrt'}\n"
     ]
    }
   ],
   "source": [
    "print(inverse_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 534ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "1/1 [==============================] - 0s 96ms/step\n",
      "1/1 [==============================] - 0s 103ms/step\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "1/1 [==============================] - 0s 99ms/step\n",
      "1/1 [==============================] - 0s 92ms/step\n",
      "for non-vgg model :\n",
      " ['himbul', 'rebimg', 'himbul', 'rebimg']\n",
      "for vgg model :\n",
      " ['cmnmyn', 'cmnmyn', 'cmnmyn', 'cmnmyn']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "img1 = image.load_img('new_valid/great_tit.jpg', target_size=(224, 224))\n",
    "img2 = image.load_img('new_valid/chestnut_bellied_rock_thrush.jpg', target_size=(224, 224))\n",
    "img3 = image.load_img('new_valid/large_billed_crow.jpg', target_size=(224, 224))\n",
    "img4 = image.load_img('new_valid/himalyan_bulbul.jpg', target_size=(224, 224))\n",
    "\n",
    "predicted_indices = []\n",
    "predicted_indices_vgg = []\n",
    "\n",
    "for img in [img1, img2, img3, img4]:\n",
    "    img = image.img_to_array(img)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    pred = np.argmax(model.predict(img))\n",
    "    pred2 = np.argmax(some_tuned_model.predict(img))\n",
    "    \n",
    "    predicted_indices.append(pred)\n",
    "    predicted_indices_vgg.append(pred2) \n",
    "\n",
    "predicted_labels = [inverse_dict[index] for index in predicted_indices]\n",
    "predicted_labels_vgg = [inverse_dict[index] for index in predicted_indices_vgg]\n",
    "\n",
    "print(\"for non-vgg model :\\n\", predicted_labels)\n",
    "print(\"for vgg model :\\n\", predicted_labels_vgg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
